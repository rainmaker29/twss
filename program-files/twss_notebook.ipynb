{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.9"
    },
    "colab": {
      "name": "twss_notebook.ipynb",
      "provenance": [],
      "collapsed_sections": []
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "ejy1UJbVkkT0",
        "colab_type": "code",
        "outputId": "24672c4b-467e-4b89-b0b1-650c6b323b1c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import seaborn as sns\n",
        "from sklearn import preprocessing, decomposition, model_selection, metrics, pipeline\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
        "from sklearn.decomposition import TruncatedSVD\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "from sklearn.svm import SVC\n",
        "from nltk import word_tokenize\n",
        "from nltk.corpus import stopwords\n",
        "import nltk\n",
        "nltk.download()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "NLTK Downloader\n",
            "---------------------------------------------------------------------------\n",
            "    d) Download   l) List    u) Update   c) Config   h) Help   q) Quit\n",
            "---------------------------------------------------------------------------\n",
            "Downloader> d\n",
            "\n",
            "Download which package (l=list; x=cancel)?\n",
            "  Identifier> all\n",
            "    Downloading collection 'all'\n",
            "       | \n",
            "       | Downloading package abc to /root/nltk_data...\n",
            "       |   Unzipping corpora/abc.zip.\n",
            "       | Downloading package alpino to /root/nltk_data...\n",
            "       |   Unzipping corpora/alpino.zip.\n",
            "       | Downloading package biocreative_ppi to /root/nltk_data...\n",
            "       |   Unzipping corpora/biocreative_ppi.zip.\n",
            "       | Downloading package brown to /root/nltk_data...\n",
            "       |   Unzipping corpora/brown.zip.\n",
            "       | Downloading package brown_tei to /root/nltk_data...\n",
            "       |   Unzipping corpora/brown_tei.zip.\n",
            "       | Downloading package cess_cat to /root/nltk_data...\n",
            "       |   Unzipping corpora/cess_cat.zip.\n",
            "       | Downloading package cess_esp to /root/nltk_data...\n",
            "       |   Unzipping corpora/cess_esp.zip.\n",
            "       | Downloading package chat80 to /root/nltk_data...\n",
            "       |   Unzipping corpora/chat80.zip.\n",
            "       | Downloading package city_database to /root/nltk_data...\n",
            "       |   Unzipping corpora/city_database.zip.\n",
            "       | Downloading package cmudict to /root/nltk_data...\n",
            "       |   Unzipping corpora/cmudict.zip.\n",
            "       | Downloading package comparative_sentences to\n",
            "       |     /root/nltk_data...\n",
            "       |   Unzipping corpora/comparative_sentences.zip.\n",
            "       | Downloading package comtrans to /root/nltk_data...\n",
            "       | Downloading package conll2000 to /root/nltk_data...\n",
            "       |   Unzipping corpora/conll2000.zip.\n",
            "       | Downloading package conll2002 to /root/nltk_data...\n",
            "       |   Unzipping corpora/conll2002.zip.\n",
            "       | Downloading package conll2007 to /root/nltk_data...\n",
            "       | Downloading package crubadan to /root/nltk_data...\n",
            "       |   Unzipping corpora/crubadan.zip.\n",
            "       | Downloading package dependency_treebank to /root/nltk_data...\n",
            "       |   Unzipping corpora/dependency_treebank.zip.\n",
            "       | Downloading package dolch to /root/nltk_data...\n",
            "       |   Unzipping corpora/dolch.zip.\n",
            "       | Downloading package europarl_raw to /root/nltk_data...\n",
            "       |   Unzipping corpora/europarl_raw.zip.\n",
            "       | Downloading package floresta to /root/nltk_data...\n",
            "       |   Unzipping corpora/floresta.zip.\n",
            "       | Downloading package framenet_v15 to /root/nltk_data...\n",
            "       |   Unzipping corpora/framenet_v15.zip.\n",
            "       | Downloading package framenet_v17 to /root/nltk_data...\n",
            "       |   Unzipping corpora/framenet_v17.zip.\n",
            "       | Downloading package gazetteers to /root/nltk_data...\n",
            "       |   Unzipping corpora/gazetteers.zip.\n",
            "       | Downloading package genesis to /root/nltk_data...\n",
            "       |   Unzipping corpora/genesis.zip.\n",
            "       | Downloading package gutenberg to /root/nltk_data...\n",
            "       |   Unzipping corpora/gutenberg.zip.\n",
            "       | Downloading package ieer to /root/nltk_data...\n",
            "       |   Unzipping corpora/ieer.zip.\n",
            "       | Downloading package inaugural to /root/nltk_data...\n",
            "       |   Unzipping corpora/inaugural.zip.\n",
            "       | Downloading package indian to /root/nltk_data...\n",
            "       |   Unzipping corpora/indian.zip.\n",
            "       | Downloading package jeita to /root/nltk_data...\n",
            "       | Downloading package kimmo to /root/nltk_data...\n",
            "       |   Unzipping corpora/kimmo.zip.\n",
            "       | Downloading package knbc to /root/nltk_data...\n",
            "       | Downloading package lin_thesaurus to /root/nltk_data...\n",
            "       |   Unzipping corpora/lin_thesaurus.zip.\n",
            "       | Downloading package mac_morpho to /root/nltk_data...\n",
            "       |   Unzipping corpora/mac_morpho.zip.\n",
            "       | Downloading package machado to /root/nltk_data...\n",
            "       | Downloading package masc_tagged to /root/nltk_data...\n",
            "       | Downloading package moses_sample to /root/nltk_data...\n",
            "       |   Unzipping models/moses_sample.zip.\n",
            "       | Downloading package movie_reviews to /root/nltk_data...\n",
            "       |   Unzipping corpora/movie_reviews.zip.\n",
            "       | Downloading package names to /root/nltk_data...\n",
            "       |   Unzipping corpora/names.zip.\n",
            "       | Downloading package nombank.1.0 to /root/nltk_data...\n",
            "       | Downloading package nps_chat to /root/nltk_data...\n",
            "       |   Unzipping corpora/nps_chat.zip.\n",
            "       | Downloading package omw to /root/nltk_data...\n",
            "       |   Unzipping corpora/omw.zip.\n",
            "       | Downloading package opinion_lexicon to /root/nltk_data...\n",
            "       |   Unzipping corpora/opinion_lexicon.zip.\n",
            "       | Downloading package paradigms to /root/nltk_data...\n",
            "       |   Unzipping corpora/paradigms.zip.\n",
            "       | Downloading package pil to /root/nltk_data...\n",
            "       |   Unzipping corpora/pil.zip.\n",
            "       | Downloading package pl196x to /root/nltk_data...\n",
            "       |   Unzipping corpora/pl196x.zip.\n",
            "       | Downloading package ppattach to /root/nltk_data...\n",
            "       |   Unzipping corpora/ppattach.zip.\n",
            "       | Downloading package problem_reports to /root/nltk_data...\n",
            "       |   Unzipping corpora/problem_reports.zip.\n",
            "       | Downloading package propbank to /root/nltk_data...\n",
            "       | Downloading package ptb to /root/nltk_data...\n",
            "       |   Unzipping corpora/ptb.zip.\n",
            "       | Downloading package product_reviews_1 to /root/nltk_data...\n",
            "       |   Unzipping corpora/product_reviews_1.zip.\n",
            "       | Downloading package product_reviews_2 to /root/nltk_data...\n",
            "       |   Unzipping corpora/product_reviews_2.zip.\n",
            "       | Downloading package pros_cons to /root/nltk_data...\n",
            "       |   Unzipping corpora/pros_cons.zip.\n",
            "       | Downloading package qc to /root/nltk_data...\n",
            "       |   Unzipping corpora/qc.zip.\n",
            "       | Downloading package reuters to /root/nltk_data...\n",
            "       | Downloading package rte to /root/nltk_data...\n",
            "       |   Unzipping corpora/rte.zip.\n",
            "       | Downloading package semcor to /root/nltk_data...\n",
            "       | Downloading package senseval to /root/nltk_data...\n",
            "       |   Unzipping corpora/senseval.zip.\n",
            "       | Downloading package sentiwordnet to /root/nltk_data...\n",
            "       |   Unzipping corpora/sentiwordnet.zip.\n",
            "       | Downloading package sentence_polarity to /root/nltk_data...\n",
            "       |   Unzipping corpora/sentence_polarity.zip.\n",
            "       | Downloading package shakespeare to /root/nltk_data...\n",
            "       |   Unzipping corpora/shakespeare.zip.\n",
            "       | Downloading package sinica_treebank to /root/nltk_data...\n",
            "       |   Unzipping corpora/sinica_treebank.zip.\n",
            "       | Downloading package smultron to /root/nltk_data...\n",
            "       |   Unzipping corpora/smultron.zip.\n",
            "       | Downloading package state_union to /root/nltk_data...\n",
            "       |   Unzipping corpora/state_union.zip.\n",
            "       | Downloading package stopwords to /root/nltk_data...\n",
            "       |   Unzipping corpora/stopwords.zip.\n",
            "       | Downloading package subjectivity to /root/nltk_data...\n",
            "       |   Unzipping corpora/subjectivity.zip.\n",
            "       | Downloading package swadesh to /root/nltk_data...\n",
            "       |   Unzipping corpora/swadesh.zip.\n",
            "       | Downloading package switchboard to /root/nltk_data...\n",
            "       |   Unzipping corpora/switchboard.zip.\n",
            "       | Downloading package timit to /root/nltk_data...\n",
            "       |   Unzipping corpora/timit.zip.\n",
            "       | Downloading package toolbox to /root/nltk_data...\n",
            "       |   Unzipping corpora/toolbox.zip.\n",
            "       | Downloading package treebank to /root/nltk_data...\n",
            "       |   Unzipping corpora/treebank.zip.\n",
            "       | Downloading package twitter_samples to /root/nltk_data...\n",
            "       |   Unzipping corpora/twitter_samples.zip.\n",
            "       | Downloading package udhr to /root/nltk_data...\n",
            "       |   Unzipping corpora/udhr.zip.\n",
            "       | Downloading package udhr2 to /root/nltk_data...\n",
            "       |   Unzipping corpora/udhr2.zip.\n",
            "       | Downloading package unicode_samples to /root/nltk_data...\n",
            "       |   Unzipping corpora/unicode_samples.zip.\n",
            "       | Downloading package universal_treebanks_v20 to\n",
            "       |     /root/nltk_data...\n",
            "       | Downloading package verbnet to /root/nltk_data...\n",
            "       |   Unzipping corpora/verbnet.zip.\n",
            "       | Downloading package verbnet3 to /root/nltk_data...\n",
            "       |   Unzipping corpora/verbnet3.zip.\n",
            "       | Downloading package webtext to /root/nltk_data...\n",
            "       |   Unzipping corpora/webtext.zip.\n",
            "       | Downloading package wordnet to /root/nltk_data...\n",
            "       |   Unzipping corpora/wordnet.zip.\n",
            "       | Downloading package wordnet_ic to /root/nltk_data...\n",
            "       |   Unzipping corpora/wordnet_ic.zip.\n",
            "       | Downloading package words to /root/nltk_data...\n",
            "       |   Unzipping corpora/words.zip.\n",
            "       | Downloading package ycoe to /root/nltk_data...\n",
            "       |   Unzipping corpora/ycoe.zip.\n",
            "       | Downloading package rslp to /root/nltk_data...\n",
            "       |   Unzipping stemmers/rslp.zip.\n",
            "       | Downloading package maxent_treebank_pos_tagger to\n",
            "       |     /root/nltk_data...\n",
            "       |   Unzipping taggers/maxent_treebank_pos_tagger.zip.\n",
            "       | Downloading package universal_tagset to /root/nltk_data...\n",
            "       |   Unzipping taggers/universal_tagset.zip.\n",
            "       | Downloading package maxent_ne_chunker to /root/nltk_data...\n",
            "       |   Unzipping chunkers/maxent_ne_chunker.zip.\n",
            "       | Downloading package punkt to /root/nltk_data...\n",
            "       |   Unzipping tokenizers/punkt.zip.\n",
            "       | Downloading package book_grammars to /root/nltk_data...\n",
            "       |   Unzipping grammars/book_grammars.zip.\n",
            "       | Downloading package sample_grammars to /root/nltk_data...\n",
            "       |   Unzipping grammars/sample_grammars.zip.\n",
            "       | Downloading package spanish_grammars to /root/nltk_data...\n",
            "       |   Unzipping grammars/spanish_grammars.zip.\n",
            "       | Downloading package basque_grammars to /root/nltk_data...\n",
            "       |   Unzipping grammars/basque_grammars.zip.\n",
            "       | Downloading package large_grammars to /root/nltk_data...\n",
            "       |   Unzipping grammars/large_grammars.zip.\n",
            "       | Downloading package tagsets to /root/nltk_data...\n",
            "       |   Unzipping help/tagsets.zip.\n",
            "       | Downloading package snowball_data to /root/nltk_data...\n",
            "       | Downloading package bllip_wsj_no_aux to /root/nltk_data...\n",
            "       |   Unzipping models/bllip_wsj_no_aux.zip.\n",
            "       | Downloading package word2vec_sample to /root/nltk_data...\n",
            "       |   Unzipping models/word2vec_sample.zip.\n",
            "       | Downloading package panlex_swadesh to /root/nltk_data...\n",
            "       | Downloading package mte_teip5 to /root/nltk_data...\n",
            "       |   Unzipping corpora/mte_teip5.zip.\n",
            "       | Downloading package averaged_perceptron_tagger to\n",
            "       |     /root/nltk_data...\n",
            "       |   Unzipping taggers/averaged_perceptron_tagger.zip.\n",
            "       | Downloading package averaged_perceptron_tagger_ru to\n",
            "       |     /root/nltk_data...\n",
            "       |   Unzipping taggers/averaged_perceptron_tagger_ru.zip.\n",
            "       | Downloading package perluniprops to /root/nltk_data...\n",
            "       |   Unzipping misc/perluniprops.zip.\n",
            "       | Downloading package nonbreaking_prefixes to\n",
            "       |     /root/nltk_data...\n",
            "       |   Unzipping corpora/nonbreaking_prefixes.zip.\n",
            "       | Downloading package vader_lexicon to /root/nltk_data...\n",
            "       | Downloading package porter_test to /root/nltk_data...\n",
            "       |   Unzipping stemmers/porter_test.zip.\n",
            "       | Downloading package wmt15_eval to /root/nltk_data...\n",
            "       |   Unzipping models/wmt15_eval.zip.\n",
            "       | Downloading package mwa_ppdb to /root/nltk_data...\n",
            "       |   Unzipping misc/mwa_ppdb.zip.\n",
            "       | \n",
            "     Done downloading collection all\n",
            "\n",
            "---------------------------------------------------------------------------\n",
            "    d) Download   l) List    u) Update   c) Config   h) Help   q) Quit\n",
            "---------------------------------------------------------------------------\n",
            "Downloader> q\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JPkxw8Knk-D5",
        "colab_type": "code",
        "outputId": "0b1d24f9-19be-4456-dd6b-a3912306594c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 124
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MiNuhDyHkkVG",
        "colab_type": "code",
        "outputId": "69f8a371-83e0-473b-d6d2-45a3585efd75",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        }
      },
      "source": [
        "fml = pd.read_csv('drive/My Drive/twss/fml.txt',sep=\"\\n\",header=None)\n",
        "fml.columns=['text']\n",
        "fml.head()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>I downloaded an application for my phone that ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>My girlfriend said \"It's funny how every time ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>My girlfriend told me she was bored. During sex.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>I have a condition that, when I pull my foresk...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>My boyfriend decided to give me a hickey. Too ...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                text\n",
              "0  I downloaded an application for my phone that ...\n",
              "1  My girlfriend said \"It's funny how every time ...\n",
              "2  My girlfriend told me she was bored. During sex. \n",
              "3  I have a condition that, when I pull my foresk...\n",
              "4  My boyfriend decided to give me a hickey. Too ..."
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JvnIw72XkkW2",
        "colab_type": "code",
        "outputId": "b2c3dc53-f8fd-429d-cf81-e54041de3e20",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        }
      },
      "source": [
        "tfln = pd.read_csv('drive/My Drive/twss/tfln.onesent.txt',sep=\"\\n\",header=None,encoding='latin')\n",
        "tfln.columns=['text']\n",
        "tfln.head()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>she pulled the sheets over her head to blow me...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>He just ordered a bottle of Beam at an Italian...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Well if my looks don't work with her I'll eat ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>If you don't remember anything tomorrow, this ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>We decided to cut you off after you insisted o...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                text\n",
              "0  she pulled the sheets over her head to blow me...\n",
              "1  He just ordered a bottle of Beam at an Italian...\n",
              "2  Well if my looks don't work with her I'll eat ...\n",
              "3  If you don't remember anything tomorrow, this ...\n",
              "4  We decided to cut you off after you insisted o..."
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fiXCb95NkkXv",
        "colab_type": "code",
        "outputId": "dce7fe58-7217-4feb-dffc-516f2abcb28c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 244
        }
      },
      "source": [
        "usa = pd.read_csv('drive/My Drive/twss/usaquotes.txt',sep=\"\\n\",header=None,error_bad_lines=False)\n",
        "usa.columns = ['text']\n",
        "usa.head()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "b'Skipping line 580: expected 1 fields, saw 2\\nSkipping line 627: expected 1 fields, saw 2\\nSkipping line 639: expected 1 fields, saw 2\\nSkipping line 646: expected 1 fields, saw 2\\nSkipping line 650: expected 1 fields, saw 2\\nSkipping line 651: expected 1 fields, saw 3\\nSkipping line 733: expected 1 fields, saw 6\\nSkipping line 790: expected 1 fields, saw 2\\nSkipping line 837: expected 1 fields, saw 4\\nSkipping line 851: expected 1 fields, saw 2\\nSkipping line 920: expected 1 fields, saw 3\\nSkipping line 977: expected 1 fields, saw 2\\nSkipping line 989: expected 1 fields, saw 2\\nSkipping line 1245: expected 1 fields, saw 2\\nSkipping line 1626: expected 1 fields, saw 3\\nSkipping line 1796: expected 1 fields, saw 2\\nSkipping line 1831: expected 1 fields, saw 3\\nSkipping line 2021: expected 1 fields, saw 2\\nSkipping line 2125: expected 1 fields, saw 2\\nSkipping line 2206: expected 1 fields, saw 2\\nSkipping line 2211: expected 1 fields, saw 2\\nSkipping line 2624: expected 1 fields, saw 2\\nSkipping line 2726: expected 1 fields, saw 2\\nSkipping line 2743: expected 1 fields, saw 2\\nSkipping line 2871: expected 1 fields, saw 2\\nSkipping line 2894: expected 1 fields, saw 2\\nSkipping line 2898: expected 1 fields, saw 2\\nSkipping line 2937: expected 1 fields, saw 2\\nSkipping line 3065: expected 1 fields, saw 4\\nSkipping line 3157: expected 1 fields, saw 2\\nSkipping line 3159: expected 1 fields, saw 2\\nSkipping line 3237: expected 1 fields, saw 3\\nSkipping line 3274: expected 1 fields, saw 3\\nSkipping line 3336: expected 1 fields, saw 4\\nSkipping line 3337: expected 1 fields, saw 6\\nSkipping line 3372: expected 1 fields, saw 2\\nSkipping line 3375: expected 1 fields, saw 2\\nSkipping line 3440: expected 1 fields, saw 2\\nSkipping line 3467: expected 1 fields, saw 3\\nSkipping line 3509: expected 1 fields, saw 3\\nSkipping line 3517: expected 1 fields, saw 6\\nSkipping line 3528: expected 1 fields, saw 2\\nSkipping line 3573: expected 1 fields, saw 2\\nSkipping line 3579: expected 1 fields, saw 2\\nSkipping line 3581: expected 1 fields, saw 2\\nSkipping line 3600: expected 1 fields, saw 2\\nSkipping line 3608: expected 1 fields, saw 2\\nSkipping line 3662: expected 1 fields, saw 2\\nSkipping line 3782: expected 1 fields, saw 3\\nSkipping line 4083: expected 1 fields, saw 2\\n'\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>We have too many high sounding words, and too ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>The reins of government have been so long slac...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Shall we be despised by foreign powers for hes...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Deliver me from your cold phlegmatic preachers...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>I regret the narrow contracted education of th...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                text\n",
              "0  We have too many high sounding words, and too ...\n",
              "1  The reins of government have been so long slac...\n",
              "2  Shall we be despised by foreign powers for hes...\n",
              "3  Deliver me from your cold phlegmatic preachers...\n",
              "4  I regret the narrow contracted education of th..."
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YM4m0cODkkYs",
        "colab_type": "code",
        "outputId": "5f2607bc-b612-4ff3-846a-2c18ddb3be70",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        }
      },
      "source": [
        "twss = pd.read_csv('drive/My Drive/twss/twssstories.txt',sep=\"\\n\",header=None,encoding='latin')\n",
        "twss.columns=['text']\n",
        "twss.head()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Put it back in, it's still moist in the middle.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Now if I can just get it in the hole, I'll sho...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>...a great penetration!</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>That just kind of squirted out there, didn't it!</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Oh it feels so good, you just insert here and ...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                text\n",
              "0    Put it back in, it's still moist in the middle.\n",
              "1  Now if I can just get it in the hole, I'll sho...\n",
              "2                            ...a great penetration!\n",
              "3   That just kind of squirted out there, didn't it!\n",
              "4  Oh it feels so good, you just insert here and ..."
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l_9cDM0fkkZm",
        "colab_type": "code",
        "outputId": "02065101-609d-4c1e-ea9c-a2e6d54f6a64",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 86
        }
      },
      "source": [
        "print(\"fml : \",len(fml))\n",
        "print(\"tfln : \",len(tfln))\n",
        "print(\"usa : \",len(usa))\n",
        "print(\"twss : \",len(twss))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "fml :  1767\n",
            "tfln :  11869\n",
            "usa :  4066\n",
            "twss :  2027\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v9w0fmm2kkaO",
        "colab_type": "code",
        "outputId": "d74cb7d5-38e7-472a-f79c-f3029fc8c103",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        }
      },
      "source": [
        "twss['target'] = [1]*2027\n",
        "twss.head()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "      <th>target</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Put it back in, it's still moist in the middle.</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Now if I can just get it in the hole, I'll sho...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>...a great penetration!</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>That just kind of squirted out there, didn't it!</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Oh it feels so good, you just insert here and ...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                text  target\n",
              "0    Put it back in, it's still moist in the middle.       1\n",
              "1  Now if I can just get it in the hole, I'll sho...       1\n",
              "2                            ...a great penetration!       1\n",
              "3   That just kind of squirted out there, didn't it!       1\n",
              "4  Oh it feels so good, you just insert here and ...       1"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XGaRtjzzkkay",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "usa = usa.loc[:666,:]\n",
        "tfln = tfln.loc[:666,:]\n",
        "fml = fml.loc[:666,:]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kxrl7gE-kkbc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "usa['target'] = [0]*667"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2uIuVRpgkkcD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "tfln['target'] = [0]*667\n",
        "fml['target'] = [0]*667"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Va9JIgS2kkct",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df = pd.concat([twss,usa,tfln,fml],ignore_index=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XJkl1Raqkkdk",
        "colab_type": "code",
        "outputId": "6c6f92f4-23dd-4e86-9886-a53d252413b1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        }
      },
      "source": [
        "df"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "      <th>target</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Put it back in, it's still moist in the middle.</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Now if I can just get it in the hole, I'll sho...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>...a great penetration!</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>That just kind of squirted out there, didn't it!</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Oh it feels so good, you just insert here and ...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4023</th>\n",
              "      <td>While my wife was watching me get undressed sh...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4024</th>\n",
              "      <td>My boyfriend came to my workplace and presente...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4025</th>\n",
              "      <td>I was laying on the bed, naked, waiting for my...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4026</th>\n",
              "      <td>I hung out with the guy I've liked for the fir...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4027</th>\n",
              "      <td>I decided to not go to a strip club for the se...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>4028 rows × 2 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                   text  target\n",
              "0       Put it back in, it's still moist in the middle.       1\n",
              "1     Now if I can just get it in the hole, I'll sho...       1\n",
              "2                               ...a great penetration!       1\n",
              "3      That just kind of squirted out there, didn't it!       1\n",
              "4     Oh it feels so good, you just insert here and ...       1\n",
              "...                                                 ...     ...\n",
              "4023  While my wife was watching me get undressed sh...       0\n",
              "4024  My boyfriend came to my workplace and presente...       0\n",
              "4025  I was laying on the bed, naked, waiting for my...       0\n",
              "4026  I hung out with the guy I've liked for the fir...       0\n",
              "4027  I decided to not go to a strip club for the se...       0\n",
              "\n",
              "[4028 rows x 2 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nxV0ITt_kkeN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df = df.sample(frac=1).reset_index(drop=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SOMT3aEIkke6",
        "colab_type": "code",
        "outputId": "be3fe844-5485-4eac-d975-d670c5a4e526",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        }
      },
      "source": [
        "df"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "      <th>target</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>It's sooo cute when you nibble it softly like ...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>I finally felt ready to take my bra off during...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>KEVIN! Stop slapping it like that! Just smooth...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>I cant yet im literally covered in lube but I ...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>My ass is really sore, but I like it a lot.</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4023</th>\n",
              "      <td>I know I'm her Sunday school teacher. I just f...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4024</th>\n",
              "      <td>I'm now at that point where it just feels natu...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4025</th>\n",
              "      <td>You just begged me to mute the porn and watch ...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4026</th>\n",
              "      <td>There are two thoughts that will ensure succes...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4027</th>\n",
              "      <td>I said to my wife that I wished I had met her ...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>4028 rows × 2 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                   text  target\n",
              "0     It's sooo cute when you nibble it softly like ...       1\n",
              "1     I finally felt ready to take my bra off during...       0\n",
              "2     KEVIN! Stop slapping it like that! Just smooth...       1\n",
              "3     I cant yet im literally covered in lube but I ...       0\n",
              "4           My ass is really sore, but I like it a lot.       1\n",
              "...                                                 ...     ...\n",
              "4023  I know I'm her Sunday school teacher. I just f...       0\n",
              "4024  I'm now at that point where it just feels natu...       0\n",
              "4025  You just begged me to mute the porn and watch ...       0\n",
              "4026  There are two thoughts that will ensure succes...       0\n",
              "4027  I said to my wife that I wished I had met her ...       0\n",
              "\n",
              "[4028 rows x 2 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qJMxnOnXkkff",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "y = df['target']\n",
        "df.drop(['target'],inplace=True,axis=1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F5YY-iMxkkf-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "xtrain,xvalid,ytrain,yvalid= train_test_split(df.text.values,y,stratify=y,random_state=42,test_size=0.1,shuffle=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Fe8FQxfZkkgb",
        "colab_type": "code",
        "outputId": "744f07f0-0924-4161-90ac-47d58e298854",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "print(xtrain.shape,xvalid.shape)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(3625,) (403,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1wjurGPNkkhG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "tfv = TfidfVectorizer(min_df=3,  max_features=None, \n",
        "            strip_accents='unicode', analyzer='word',token_pattern=r'\\w{1,}',\n",
        "            ngram_range=(1, 3), use_idf=1,smooth_idf=1,sublinear_tf=1,\n",
        "            stop_words = 'english')\n",
        "\n",
        "tfv.fit(list(xtrain) + list(xvalid))\n",
        "xtrain_tfv =  tfv.transform(xtrain) \n",
        "xvalid_tfv = tfv.transform(xvalid)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZRyJq1iIkkhh",
        "colab_type": "code",
        "outputId": "f31dbc52-6100-48b3-9632-93160430d472",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "clf = LogisticRegression(C=1.0)\n",
        "clf.fit(xtrain_tfv, ytrain)\n",
        "predictions = clf.predict(xvalid_tfv)\n",
        "\n",
        "print(metrics.accuracy_score(predictions,yvalid))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.9181141439205955\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P6bmznu9kkiG",
        "colab_type": "code",
        "outputId": "755957ad-8be5-4c11-954a-f36a50faebf5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "clf = MultinomialNB()\n",
        "clf.fit(xtrain_tfv, ytrain)\n",
        "predictions = clf.predict(xvalid_tfv)\n",
        "\n",
        "print(metrics.accuracy_score(predictions,yvalid))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.9330024813895782\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gUgIINv3kkii",
        "colab_type": "code",
        "outputId": "175950f7-4101-466b-ce05-aa5823da3c96",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "svd = decomposition.TruncatedSVD(n_components=120)\n",
        "svd.fit(xtrain_tfv)\n",
        "xtrain_svd = svd.transform(xtrain_tfv)\n",
        "xvalid_svd = svd.transform(xvalid_tfv)\n",
        "\n",
        "# Scale the data obtained from SVD. Renaming variable to reuse without scaling.\n",
        "scl = preprocessing.StandardScaler()\n",
        "scl.fit(xtrain_svd)\n",
        "xtrain_svd_scl = scl.transform(xtrain_svd)\n",
        "xvalid_svd_scl = scl.transform(xvalid_svd)\n",
        "\n",
        "clf = SVC(C=1.0, probability=True) # since we need probabilities\n",
        "clf.fit(xtrain_svd_scl, ytrain)\n",
        "predictions = clf.predict(xvalid_svd_scl)\n",
        "\n",
        "print(metrics.accuracy_score(predictions,yvalid))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.913151364764268\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WKWfgQldkkjF",
        "colab_type": "code",
        "outputId": "066f261f-7b35-482f-c8ac-ffbb98a31243",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "import xgboost\n",
        "\n",
        "xgb = xgboost.XGBClassifier(n_thread=10)\n",
        "xgb.fit(xtrain_tfv,ytrain)\n",
        "\n",
        "predictions = xgb.predict(xvalid_tfv)\n",
        "\n",
        "print(metrics.accuracy_score(predictions,yvalid))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.8287841191066998\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DOTmgJYDkkju",
        "colab_type": "code",
        "outputId": "89cd04c8-d3da-4a88-84a8-7649e78bd2b6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "xgb.fit(xtrain_svd,ytrain)\n",
        "\n",
        "predictions = xgb.predict(xvalid_svd)\n",
        "\n",
        "print(metrics.accuracy_score(predictions,yvalid))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.8709677419354839\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "58n9g5xsl7sc",
        "colab_type": "code",
        "outputId": "9521cd98-9bae-450a-ab81-38389c11790c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 245
        }
      },
      "source": [
        "\n",
        "\n",
        "mll_scorer = metrics.make_scorer(metrics.accuracy_score, greater_is_better=True, needs_proba=False)\n",
        "\n",
        "\n",
        "\n",
        "nb_model = MultinomialNB()\n",
        "\n",
        "# Create the pipeline \n",
        "clf = pipeline.Pipeline([('nb', nb_model)])\n",
        "\n",
        "# parameter grid\n",
        "param_grid = {'nb__alpha': [0.001, 0.01, 0.1, 1, 10, 100]}\n",
        "\n",
        "# Initialize Grid Search Model\n",
        "model = GridSearchCV(estimator=clf, param_grid=param_grid, scoring=mll_scorer,\n",
        "                                 verbose=10, n_jobs=-1, iid=True, refit=True, cv=2)\n",
        "\n",
        "# Fit Grid Search Model\n",
        "model.fit(xtrain_tfv, ytrain)  # we can use the full data here but im only using xtrain. \n",
        "print(\"Best score: %0.3f\" % model.best_score_)\n",
        "print(\"Best parameters set:\")\n",
        "best_parameters = model.best_estimator_.get_params()\n",
        "for param_name in sorted(param_grid.keys()):\n",
        "    print(\"\\t%s: %r\" % (param_name, best_parameters[param_name]))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Fitting 2 folds for each of 6 candidates, totalling 12 fits\n",
            "Best score: 0.898\n",
            "Best parameters set:\n",
            "\tnb__alpha: 0.1\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n",
            "[Parallel(n_jobs=-1)]: Done   1 tasks      | elapsed:    0.0s\n",
            "[Parallel(n_jobs=-1)]: Batch computation too fast (0.0163s.) Setting batch_size=2.\n",
            "[Parallel(n_jobs=-1)]: Done   4 tasks      | elapsed:    0.0s\n",
            "[Parallel(n_jobs=-1)]: Batch computation too fast (0.0302s.) Setting batch_size=4.\n",
            "[Parallel(n_jobs=-1)]: Done  12 out of  12 | elapsed:    0.1s finished\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/model_selection/_search.py:823: FutureWarning: The parameter 'iid' is deprecated in 0.22 and will be removed in 0.24.\n",
            "  \"removed in 0.24.\", FutureWarning\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ytR1BNtwmk0X",
        "colab_type": "code",
        "outputId": "e8098338-e3da-4152-cdfd-f621da38e89c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "clf = MultinomialNB(alpha=0.1)\n",
        "clf.fit(xtrain_tfv, ytrain)\n",
        "predictions = clf.predict(xvalid_tfv)\n",
        "\n",
        "print(metrics.accuracy_score(predictions,yvalid))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.9404466501240695\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lVafyDHOm0Qk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def tfconverter(x):\n",
        "  tfv = TfidfVectorizer(min_df=3,  max_features=None, \n",
        "            strip_accents='unicode', analyzer='word',token_pattern=r'\\w{1,}',\n",
        "            ngram_range=(1, 3), use_idf=1,smooth_idf=1,sublinear_tf=1,\n",
        "            stop_words = 'english')\n",
        "  tfv.fit(list(xtrain) + list(xvalid))\n",
        "\n",
        "  return tfv.transform(x)\n",
        "  \n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hTUAIB6Fnef-",
        "colab_type": "code",
        "outputId": "02715ac7-a636-453a-c26b-4e54b0c7b243",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "source": [
        "x = tfconverter([input()])\n",
        "clf = MultinomialNB(alpha=0.1)\n",
        "clf.fit(xtrain_tfv, ytrain)\n",
        "res = clf.predict(x)\n",
        "\n",
        "if res == np.array([0]):\n",
        "  print(\"Nope\")\n",
        "else:\n",
        "  print(\"That's what she said\")\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "i cant take it anymore\n",
            "That's what she said\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XZrga250osqc",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "c5e1cac1-146a-49d8-83c3-c5a85b798fdd"
      },
      "source": [
        "clf"
      ],
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "MultinomialNB(alpha=0.1, class_prior=None, fit_prior=True)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 51
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A7GQVRrTPNxj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pickle\n",
        "pickle.dump(clf,open('model.pkl','wb'))\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "17W-9cCfQPq_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model = pickle.load(open('model.pkl','rb'))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1SC3f3o7QUTn",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "outputId": "4eba9987-77ed-4e1a-b39a-f1627443f366"
      },
      "source": [
        "x = tfconverter([input()])\n",
        "model.predict(x)"
      ],
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "that's the wrong hole\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([1])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 56
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x_0rfyeFQedg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}